const axios = require('axios');
const { sendMessage } = require('../handles/sendMessage');

module.exports = {
  name: 'ai',
  description: 'Interact with llama3-8b API',
  usage: 'ai [your message]',
  author: 'coffee',

  async execute(senderId, args, pageAccessToken) {
    const prompt = args.join(' ');
    if (!prompt) return sendMessage(senderId, { text: "ğ’ğšğ¥ğ®ğ­ ğŸ‘‹ ğ£ğ ğ¬ğ®ğ¢ğ¬ ğğ«ğ¨ğœğ¡ğ¢ ğ¯ğ¨ğ­ğ«ğ ğœğ¡ğšğ­ğ›ğ¨ğ­,ğ•ğğ®ğ¢ğ¥ğ¥ğğ³ ğ©ğ¨ğ¬ğğ« ğ¥ğš ğªğ®ğğ¬ğ­ğ¢ğ¨ğ§ ğš ğ¯ğ¨ğ­ğ«ğ ğœğ¨ğ§ğ¯ğğ§ğšğ§ğœğ ğğ­ ğ£ğ ğ¦'ğğŸğŸğ¨ğ«ğœğğ«ğšğ¢ ğğ ğ¯ğ¨ğ®ğ¬  ğŸğ¨ğ®ğ«ğ§ğ¢ğ« ğ®ğ§ğ ğ«ğğ©ğ¨ğ§ğ¬ğ ğğŸğŸğ¢ğœğšğœğ ğŸ™‚ğŸ¤“. ğ•ğ¨ğ­ğ«ğ ğ¬ğšğ­ğ¢ğ¬ğŸğšğœğ­ğ¢ğ¨ğ§ ğğ¬ğ­ ğ¦ğš ğ©ğ«ğ¢ğ¨ğ«ğ¢ğ­Ã© ğšğ›ğ¬ğ¨ğ¥ğ®ğ ğŸ¤–. (ğ„ğğ¢ğ­Ã© ğ©ğšğ« ğƒğğ¥ğŸğš ğŸğ«ğ¨ğ¬ğ­)" }, pageAccessToken);

    try {
      const response = await axios.post(
        'https://asios-api.vercel.app/api/llama3-8b',
        { prompt },
        { headers: { 'Content-Type': 'application/json' } }
      );

      // Supposons que la rÃ©ponse est dans response.data.response ou response.data.text
      const text = response.data.response || response.data.text || "DÃ©solÃ©, je n'ai pas compris la rÃ©ponse.";

      // DÃ©coupage en morceaux de 1800 caractÃ¨res max
      const parts = [];
      for (let i = 0; i < text.length; i += 1800) {
        parts.push(text.substring(i, i + 1800));
      }

      for (const part of parts) {
        await sendMessage(senderId, { text: part }, pageAccessToken);
      }

    } catch (error) {
      console.error('AI command error:', error.message || error);
      sendMessage(senderId, { 
        text: "ğ•ğğ®ğ¢ğ¥ğ¥ğğ³ ğ«Ã©ğğ¬ğ¬ğšğ²ğğ« ğ©ğ¥ğ®ğ¬ ğ­ğšğ«ğ ğŸ™‚âœ¨,\n\n" +
              "ğ¯ğ¨ğ®ğ¬ Ãªğ­ğğ¬ ğ­ğ«Ã¨ğ¬ ğ§ğ¨ğ¦ğ›ğ«ğğ®ğ± ğğ­ ğ¦ğ¨ğ§ ğ¬ğğ«ğ¯ğğ®ğ« ğğ¬ğ­ ğ®ğ§ ğ©ğğ® ğ¬ğ®ğ«ğœğ¡ğšğ«ğ Ã©."
      }, pageAccessToken);
    }
  }
};
